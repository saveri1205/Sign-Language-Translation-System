{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of final_predict.ipynb","provenance":[{"file_id":"1pyWmje1RPLZCshSHIXmQ4j_zCqSuko05","timestamp":1639421680855}],"mount_file_id":"1pyWmje1RPLZCshSHIXmQ4j_zCqSuko05","authorship_tag":"ABX9TyNQxAyeGhrYrqVpVOImzXmc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2_bs3uk6iDPu","executionInfo":{"status":"ok","timestamp":1639380518254,"user_tz":-330,"elapsed":1664,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"outputs":[],"source":["import torch\n","from collections import Counter\n","import pandas as pd\n","import plotly.express as px\n","from sklearn.model_selection import train_test_split\n","import os\n","from glob import glob\n","from torchvision import transforms\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","from torchvision import models\n","import torch.nn as nn\n","#from torchsummary import summary\n","from torchvision import transforms, datasets, models\n","import torch\n","from torch import optim, cuda\n","from torch.utils.data import DataLoader, sampler\n","import torch.nn as nn\n","import numpy as np\n","import tqdm"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","# Data science tools\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# Image manipulations\n","from PIL import Image\n","\n","from timeit import default_timer as timer\n","\n","# Visualizations\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.rcParams['font.size'] = 14"],"metadata":{"id":"b-hbQXRci4Qj","executionInfo":{"status":"ok","timestamp":1639380520144,"user_tz":-330,"elapsed":394,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from torch import Tensor, nn\n","from torch.nn.functional import interpolate"],"metadata":{"id":"5B1XbeYKi5kB","executionInfo":{"status":"ok","timestamp":1639380521478,"user_tz":-330,"elapsed":2,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#!pip install anvil-uplink"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"cVtI0lH8sScA","executionInfo":{"status":"ok","timestamp":1639380501617,"user_tz":-330,"elapsed":4593,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}},"outputId":"8a539fb9-9e9b-4420-da75-6de17f58336b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting anvil-uplink\n","  Downloading anvil_uplink-0.3.41-py2.py3-none-any.whl (64 kB)\n","\u001b[?25l\r\u001b[K     |█████                           | 10 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n","Collecting ws4py\n","  Downloading ws4py-0.5.1.tar.gz (51 kB)\n","\u001b[?25l\r\u001b[K     |██████▍                         | 10 kB 58.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 20 kB 62.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 30 kB 69.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 40 kB 50.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 51 kB 52.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51 kB 223 kB/s \n","\u001b[?25hCollecting argparse\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n","Building wheels for collected packages: ws4py\n","  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45230 sha256=14d7d65ea5834d7407cac8325fc5e1d435a2817d28efc1c28da85345d515cb88\n","  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n","Successfully built ws4py\n","Installing collected packages: ws4py, argparse, anvil-uplink\n","Successfully installed anvil-uplink-0.3.41 argparse-1.4.0 ws4py-0.5.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","google"]}}},"metadata":{}}]},{"cell_type":"code","source":["import anvil.server\n","anvil.server.connect(\"GX22SGC2FDHQTTPZCAII7EOI-QMAS2S5WJ63WLJEI\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRgrIkVhsSTg","executionInfo":{"status":"ok","timestamp":1639380548683,"user_tz":-330,"elapsed":1074,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}},"outputId":"c66d3333-fdc8-472f-8011-b9193f2ca21b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Connecting to wss://anvil.works/uplink\n","Anvil websocket open\n","Connected to \"Default environment\" as SERVER\n"]}]},{"cell_type":"code","source":["def imshow_tensor(image, ax=None, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","\n","    if ax is None:\n","        fig, ax = plt.subplots()\n","\n","    # Set the color channel as the third dimension\n","    image = image.numpy().transpose((1, 2, 0))\n","\n","    # Reverse the preprocessing steps\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    image = std * image + mean\n","\n","    # Clip the image pixel values\n","    image = np.clip(image, 0, 1)\n","\n","    ax.imshow(image)\n","    plt.axis('off')\n","\n","    return ax, image"],"metadata":{"id":"IiOT7nMCi9Q6","executionInfo":{"status":"ok","timestamp":1639380207019,"user_tz":-330,"elapsed":1,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["traindir = f\"/content/drive/MyDrive/DATA/train\"\n","valdir = f\"/content/drive/MyDrive/DATA/test\""],"metadata":{"id":"r_ZYJ_Pui_qR","executionInfo":{"status":"ok","timestamp":1639380208826,"user_tz":-330,"elapsed":2,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["save_file_name = f'resnet50-transfer.pt'\n","checkpoint_path = f'resnet50-transfer.pth'\n","\n","# Change to fit hardware\n","batch_size = 512\n","\n","# Whether to train on a gpu\n","train_on_gpu = cuda.is_available()\n","print(f'Train on gpu: {train_on_gpu}')\n","\n","# Number of gpus\n","multi_gpu = False\n","if train_on_gpu:\n","    gpu_count = cuda.device_count()\n","    print(f'{gpu_count} gpus detected.')\n","    if gpu_count > 1:\n","        multi_gpu = True\n","    else:\n","        multi_gpu = False\n","    print(train_on_gpu,multi_gpu)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYd8xWy3jBUR","executionInfo":{"status":"ok","timestamp":1639380210600,"user_tz":-330,"elapsed":3,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}},"outputId":"d10003c6-70b3-4a01-f405-0eae2dceeb25"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on gpu: True\n","1 gpus detected.\n","True False\n"]}]},{"cell_type":"code","source":["def load_checkpoint(path):\n","    \"\"\"Load a PyTorch model checkpoint\n","\n","    Params\n","    --------\n","        path (str): saved model checkpoint. Must start with `model_name-` and end in '.pth'\n","\n","    Returns\n","    --------\n","        None, save the `model` to `path`\n","\n","    \"\"\"\n","\n","    # Get the model name\n","    model_name = path.split('-')[0]\n","    assert (model_name in ['vgg16', 'resnet50'\n","                           ]), \"Path must have the correct model name\"\n","\n","    # Load in checkpoint\n","    checkpoint = torch.load(path)\n","\n","    if model_name == 'vgg16':\n","        model = models.vgg16(pretrained=True)\n","        # Make sure to set parameters as not trainable\n","        for param in model.parameters():\n","            param.requires_grad = False\n","        model.classifier = checkpoint['classifier']\n","\n","    elif model_name == 'resnet50':\n","        model = models.resnet50(pretrained=True)\n","        # Make sure to set parameters as not trainable\n","        for param in model.parameters():\n","            param.requires_grad = False\n","        model.fc = checkpoint['fc']\n","\n","    # Load in the state dict\n","    model.load_state_dict(checkpoint['state_dict'])\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f'{total_params:,} total parameters.')\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f'{total_trainable_params:,} total gradient parameters.')\n","\n","    # Move to gpu\n","    if multi_gpu:\n","        model = nn.DataParallel(model)\n","\n","    if train_on_gpu:\n","        model = model.to('cuda')\n","\n","    # Model basics\n","    model.class_to_idx = checkpoint['class_to_idx']\n","    model.idx_to_class = checkpoint['idx_to_class']\n","    model.epochs = checkpoint['epochs']\n","\n","    # Optimizer\n","    optimizer = checkpoint['optimizer']\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    return model, optimizer"],"metadata":{"id":"w3sDsR5ajDBQ","executionInfo":{"status":"ok","timestamp":1639381953494,"user_tz":-330,"elapsed":428,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model, optimizer = load_checkpoint(path=checkpoint_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eG1og-r0rNae","executionInfo":{"status":"ok","timestamp":1639381959750,"user_tz":-330,"elapsed":4159,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}},"outputId":"d7ace456-7315-4d40-829b-10ec43d9acc4"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["24,041,571 total parameters.\n","533,539 total gradient parameters.\n"]}]},{"cell_type":"code","source":["def process_image(image_path):\n","    \"\"\"Process an image path into a PyTorch tensor\"\"\"\n","\n","    image = Image.open(image_path)\n","    # Resize\n","    img = image.resize((256, 256))\n","\n","    # Center crop\n","    width = 256\n","    height = 256\n","    new_width = 224\n","    new_height = 224\n","\n","    left = (width - new_width) / 2\n","    top = (height - new_height) / 2\n","    right = (width + new_width) / 2\n","    bottom = (height + new_height) / 2\n","    img = img.crop((left, top, right, bottom))\n","\n","    # Convert to numpy, transpose color dimension and normalize\n","    img = np.array(img).transpose((2, 0, 1)) / 256\n","\n","    # Standardization\n","    means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n","    stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n","\n","    img = img - means\n","    img = img / stds\n","\n","    img_tensor = torch.Tensor(img)\n","\n","    return img_tensor"],"metadata":{"id":"vZNB93WbrRLe","executionInfo":{"status":"ok","timestamp":1639381961387,"user_tz":-330,"elapsed":2,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from skimage import measure\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import os\n","from skimage.metrics import structural_similarity as ssim"],"metadata":{"id":"OB91tIEixVaX","executionInfo":{"status":"ok","timestamp":1639381970796,"user_tz":-330,"elapsed":389,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#function to compute the mean squared error between images\n","def mse(imageA, imageB):\n","\n","\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n","\terr /= float(imageA.shape[0] * imageA.shape[1])\n","\n","\treturn err\n","\n","#function to compute both mse and structural similarity index between two images\n","def compare_images(imageA, imageB):\n","\n","\tm = mse(imageA, imageB)\n","\ts = ssim(imageA, imageB,multichannel=True)\n","\n","\treturn s"],"metadata":{"id":"oKkQTNFrxVXc","executionInfo":{"status":"ok","timestamp":1639381972083,"user_tz":-330,"elapsed":1,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"7f0_xKAdxVPR","executionInfo":{"status":"ok","timestamp":1639381973634,"user_tz":-330,"elapsed":2,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def predict(image_path, model, topk=5):\n","    \"\"\"Make a prediction for an image using a trained model\n","\n","    Params\n","    --------\n","        image_path (str): filename of the image\n","        model (PyTorch model): trained model for inference\n","        topk (int): number of top predictions to return\n","\n","    Returns\n","        \n","    \"\"\"\n","    \n","    real_class = image_path.split('/')[-2]\n","\n","\n","    # Convert to pytorch tensor\n","    img_tensor = process_image(image_path)\n","\n","    # Resize\n","    if train_on_gpu:\n","        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n","    else:\n","        img_tensor = img_tensor.view(1, 3, 224, 224)\n","\n","    # Set to evaluation\n","    with torch.no_grad():\n","        model.eval()\n","        # Model outputs log probabilities\n","        out = model(img_tensor)\n","        ps = torch.exp(out)\n","\n","        # Find the topk predictions\n","        topk, topclass = ps.topk(topk, dim=1)\n","\n","        # Extract the actual classes and probabilities\n","        top_classes = [\n","            model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]\n","        ]\n","        top_p = topk.cpu().numpy()[0]\n","\n","        return img_tensor.cpu().squeeze(), top_p, top_classes, real_class"],"metadata":{"id":"uG94ZY10rUul","executionInfo":{"status":"ok","timestamp":1639381975248,"user_tz":-330,"elapsed":1,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["traindir = f\"/content/drive/MyDrive/DATA/train\"\n","valdir = f\"/content/drive/MyDrive/DATA/test\"\n","\n","save_file_name = f'resnet50-transfer.pt'\n","checkpoint_path = f'resnet50-transfer.pth'\n","\n","save_file_name = f'resnet50-transfer.pt'\n","checkpoint_path = f'resnet50-transfer.pth'\n","\n","# Change to fit hardware\n","batch_size = 512\n","\n","# Whether to train on a gpu\n","train_on_gpu = cuda.is_available()\n","print(f'Train on gpu: {train_on_gpu}')\n","\n","# Number of gpus\n","multi_gpu = False\n","if train_on_gpu:\n","    gpu_count = cuda.device_count()\n","    print(f'{gpu_count} gpus detected.')\n","    if gpu_count > 1:\n","        multi_gpu = True\n","    else:\n","        multi_gpu = False\n","    print(train_on_gpu,multi_gpu)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gf181CjcxonZ","executionInfo":{"status":"ok","timestamp":1639381976850,"user_tz":-330,"elapsed":3,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}},"outputId":"ff94ade7-42ab-4f97-e436-15488e4b5051"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on gpu: True\n","1 gpus detected.\n","True False\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lmicfrKuxobg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","@anvil.server.callable\n","def anvil_predict(file):\n","  print(\"inside anvil predict\")\n","  # Read the video from specified path\n","  #cam = cv2.VideoCapture(\"/content/drive/MyDrive/capstone project/v.mp4\")\n","  print(\"cam=\",type(file))\n","\n","\n","  with open(\"tempfilename_video.mp4\", 'wb') as cam:\n","    print(type(cam))\n","    cam.write(file.get_bytes())\n","\n","  cam=cv2.VideoCapture(\"tempfilename_video.mp4\")\n","\n","  currentframe = 0\n","  cur=None\n","\n","  while(True):\n","        \n","      # reading from frame\n","      ret,frame = cam.read()\n","\n","      if ret:\n","\n","          #no image to compare\n","          if(cur is None):\n","            name = 'f' + str(currentframe) + '.jpg'\n","            print ('Creating...' + name)\n","            path = '/content/drive/MyDrive/capstone project/frames'\n","            cv2.imwrite(os.path.join(path,name),frame)\n","            cur=frame\n","            currentframe += 1\n","\n","          else:\n","            s=compare_images(cur,frame)\n","            if(s<0.8):\n","              name = 'f' + str(currentframe) + '.jpg'\n","              print ('Creating...' + name)\n","              path = '/content/drive/MyDrive/capstone project/frames'\n","              cv2.imwrite(os.path.join(path,name),frame)\n","              cur=frame\n","              currentframe += 1\n","        \n","      else:\n","          break\n","    \n","  # Release all space and windows once done\n","  cam.release()\n","  cv2.destroyAllWindows()\n","\n","  x=0\n","  res=[]\n","  #to predict the class of each frame\n","  stored_images=\"/content/drive/MyDrive/capstone project/frames\"\n","  for i in range(0,currentframe):\n","\n","    if(x>currentframe):\n","      break\n","\n","    cur=\"f\"+str(x)+\".jpg\"\n","    print(\"cur=\",cur)\n","    cur_path=stored_images+\"/\"+cur\n","    img, top_p, top_classes, real_class = predict(cur_path, model,topk=1)\n","    print(top_p, top_classes)\n","    cur=cur.replace(\"f\",\"\")\n","    res.append([cur,top_classes[0]])\n","    print(res)\n","    x=x+1\n","  print(res)\n","  res=sorted(res,key=lambda x:x[0])\n","  print(res)\n","  ans=\"\"\n","\n","  for i in res:\n","    ans=ans+i[1]\n","\n","  print(ans)\n","  return ans"],"metadata":{"id":"Hc0zkmRsrXoE","executionInfo":{"status":"ok","timestamp":1639383051677,"user_tz":-330,"elapsed":410,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["anvil.server.wait_forever()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DoVG_ggus-cV","executionInfo":{"status":"error","timestamp":1639408585974,"user_tz":-330,"elapsed":8818265,"user":{"displayName":"Manasa V.L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYpkhhXDLXb5fAPNhyRD5vcF_jAf0nn9O2tMwZrQ=s64","userId":"06249057390091267787"}},"outputId":"7fa6d61f-4375-4763-ae09-d7b4b50cc764"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","Creating...f2.jpg\n","Creating...f3.jpg\n","Creating...f4.jpg\n","cur= f0.jpg\n","[0.9992818] ['W']\n","[['0.jpg', 'W']]\n","cur= f1.jpg\n","[0.99624467] ['O']\n","[['0.jpg', 'W'], ['1.jpg', 'O']]\n","cur= f2.jpg\n","[0.8999336] ['R']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R']]\n","cur= f3.jpg\n","[0.996867] ['L']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L']]\n","cur= f4.jpg\n","[0.9863879] ['D']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","WORLD\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","Creating...f2.jpg\n","Creating...f3.jpg\n","Creating...f4.jpg\n","cur= f0.jpg\n","[0.9992818] ['W']\n","[['0.jpg', 'W']]\n","cur= f1.jpg\n","[0.99624467] ['O']\n","[['0.jpg', 'W'], ['1.jpg', 'O']]\n","cur= f2.jpg\n","[0.8999336] ['R']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R']]\n","cur= f3.jpg\n","[0.996867] ['L']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L']]\n","cur= f4.jpg\n","[0.9863879] ['D']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","WORLD\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","cur= f0.jpg\n","[0.9980988] ['H']\n","[['0.jpg', 'H']]\n","cur= f1.jpg\n","[0.99316996] ['I']\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","[['0.jpg', 'H'], ['1.jpg', 'I']]\n","HI\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","Creating...f2.jpg\n","Creating...f3.jpg\n","Creating...f4.jpg\n","cur= f0.jpg\n","[0.99968034] ['W']\n","[['0.jpg', 'W']]\n","cur= f1.jpg\n","[0.999683] ['O']\n","[['0.jpg', 'W'], ['1.jpg', 'O']]\n","cur= f2.jpg\n","[0.9892739] ['R']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R']]\n","cur= f3.jpg\n","[0.99635077] ['L']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L']]\n","cur= f4.jpg\n","[0.96573794] ['D']\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","[['0.jpg', 'W'], ['1.jpg', 'O'], ['2.jpg', 'R'], ['3.jpg', 'L'], ['4.jpg', 'D']]\n","WORLD\n","inside anvil predict\n","cam= <class 'anvil._serialise.StreamingMedia'>\n","<class '_io.BufferedWriter'>\n","Creating...f0.jpg\n","Creating...f1.jpg\n","Creating...f2.jpg\n","Creating...f3.jpg\n","Creating...f4.jpg\n","cur= f0.jpg\n","[0.952277] ['E']\n","[['0.jpg', 'E']]\n","cur= f1.jpg\n","[0.9946622] ['A']\n","[['0.jpg', 'E'], ['1.jpg', 'A']]\n","cur= f2.jpg\n","[0.99488777] ['R']\n","[['0.jpg', 'E'], ['1.jpg', 'A'], ['2.jpg', 'R']]\n","cur= f3.jpg\n","[0.99517137] ['T']\n","[['0.jpg', 'E'], ['1.jpg', 'A'], ['2.jpg', 'R'], ['3.jpg', 'T']]\n","cur= f4.jpg\n","[0.9916331] ['H']\n","[['0.jpg', 'E'], ['1.jpg', 'A'], ['2.jpg', 'R'], ['3.jpg', 'T'], ['4.jpg', 'H']]\n","[['0.jpg', 'E'], ['1.jpg', 'A'], ['2.jpg', 'R'], ['3.jpg', 'T'], ['4.jpg', 'H']]\n","[['0.jpg', 'E'], ['1.jpg', 'A'], ['2.jpg', 'R'], ['3.jpg', 'T'], ['4.jpg', 'H']]\n","EARTH\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-95cac3476493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"cZOnTazmtacl"},"execution_count":null,"outputs":[]}]}